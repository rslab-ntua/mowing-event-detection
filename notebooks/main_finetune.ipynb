{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae604467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torchinfo\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "import copy\n",
    "\n",
    "\n",
    "\n",
    "from torch import nn\n",
    "from System.pos_enc import *\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from Data.MowingDetectionDataset_Parcelized import *\n",
    "from System.pos_enc import *\n",
    "from System.Engine import *\n",
    "from System.Engine_Tr import *\n",
    "from helpers.various import *\n",
    "from torchmetrics import Accuracy, ConfusionMatrix, F1Score, Recall, Precision\n",
    "from torchinfo import summary\n",
    "\n",
    "\n",
    "transforms = A.Compose([\n",
    "        #A.Normalize(mean=[-0.3357, -0.3259],#####how many channels to include?\n",
    "                   # std=[0.4688, 0.4685]),\n",
    "        ToTensorV2()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc14e352",
   "metadata": {},
   "outputs": [],
   "source": [
    "###padding is used because there is the possibility to have nan at the ts start###\n",
    "###also the argument nan_free is passed to interpolate the ts###\n",
    "train_dt = ParcelMowingDataset(root_path = root_dataset_path,labels_path = path_train, trsm = transforms,max_lenght_to_pad=48,\n",
    "                nan_free = False,mode = 'pad', interpolate = True,extra_features = True)\n",
    "train_dloader = DataLoader(train_dt, sampler=ImbalancedDatasetSampler(train_dt), \n",
    "                           batch_size=train_batch, shuffle=False, num_workers=0)\n",
    "\n",
    "val_dt = ParcelMowingDataset(root_dataset_path,labels_path = path_val, trsm = transforms, max_lenght_to_pad=48,\n",
    "                nan_free = False,mode = 'pad', interpolate = True,extra_features = True)\n",
    "val_dloader = DataLoader(val_dt, batch_size=val_batch, shuffle=False, num_workers=0)\n",
    "\n",
    "test_dt = ParcelMowingDataset(root_dataset_path,labels_path = path_test, trsm = transforms, max_lenght_to_pad=48,\n",
    "                nan_free = False,mode = 'pad', interpolate = True,extra_features = True)\n",
    "test_dloader = DataLoader(test_dt, batch_size=test_batch, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e36b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from pytorch_lightning.tuner.tuning import Tuner\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor=\"accuracy_macro/val\", mode=\"max\", patience=50),\n",
    "    ModelCheckpoint(monitor=\"accuracy_macro/val\", mode=\"max\", save_last=True),\n",
    "    LearningRateMonitor(logging_interval='epoch'),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72de34de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "model = resnet.load_from_checkpoint('./epoch=66-step=134.ckpt')\n",
    "\n",
    "# Freeze all the parameters in the network\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "# Get the number of input features for the last FC layer\n",
    "\n",
    "num_features = model.resnet1d.fc.in_features\n",
    "print('num features_in',num_features)\n",
    "# Define your new FC layer\n",
    "# For example, if you want to replace the FC layer with a new one for a different classification task:\n",
    "new_fc = nn.Linear(num_features, 5)  # num_classes is the number of classes in your new task\n",
    "\n",
    "# Replace the FC layer in the ResNet model\n",
    "model.resnet1d.fc = new_fc\n",
    "\n",
    "\n",
    "# Print trainable parameters per layer\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Layer: {name}, Trainable parameters: {param.numel()}\")\n",
    "\n",
    "        \n",
    "        \n",
    "summary(model, input_size=(1, 1, 48, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca9300a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = Pretrained_ECGTR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcf16c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "summary(test_model, input_size=(1, 1, 48, 5))\n",
    "# Print trainable parameters per layer\n",
    "for name, param in test_model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Layer: {name}, Trainable parameters: {param.numel()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469055ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "###resume from checkpoint###\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from pytorch_lightning.tuner.tuning import Tuner\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor=\"accuracy_macro/val\", mode=\"max\", patience=50),\n",
    "    ModelCheckpoint(monitor=\"accuracy_macro/val\", mode=\"max\", save_last=True),\n",
    "    LearningRateMonitor(logging_interval='epoch'),\n",
    "]\n",
    "\n",
    "model = ECGTRMODEL()\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\", \n",
    "    devices=1,\n",
    "    max_epochs=number_of_epochs,\n",
    "    callbacks=callbacks,\n",
    "    default_root_dir=save_dir,\n",
    "    enable_progress_bar = False,\n",
    "    resume_from_checkpoint = './pretrained_models_resumables/lightning_logs/version_2/checkpoints/epoch=37-step=2774.ckpt'\n",
    "    #detect_anomaly=True,\n",
    ")\n",
    "\n",
    "trainer.fit(model, train_dataloaders=train_dloader, val_dataloaders=val_dloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5d83db",
   "metadata": {},
   "outputs": [],
   "source": [
    "###finetune a pretrained model###\n",
    "\n",
    "\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from pytorch_lightning.tuner.tuning import Tuner\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor=\"accuracy_macro/val\", mode=\"max\", patience=50),\n",
    "    ModelCheckpoint(monitor=\"accuracy_macro/val\", mode=\"max\", save_last=True),\n",
    "    LearningRateMonitor(logging_interval='epoch'),\n",
    "]\n",
    "\n",
    "model = Pretrained_ECGTR()\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\", \n",
    "    devices=1,\n",
    "    max_epochs=number_of_epochs,\n",
    "    callbacks=callbacks,\n",
    "    default_root_dir=save_dir,\n",
    "    enable_progress_bar = False,\n",
    "\n",
    ")\n",
    "\n",
    "trainer.fit(model, train_dataloaders=train_dloader, val_dataloaders=val_dloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43736db",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = Pretrained_ECGTR.load_from_checkpoint('./___.ckpt')\n",
    "trainer = pl.Trainer(accelerator=\"gpu\", \n",
    "    devices=1)\n",
    "trainer.test(best_model, dataloaders=test_dloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ca2164",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####to do!!!!####\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "class_labels = ['0 times', '1 times','2 times', '3 times', '4 times']\n",
    "cm = best_model.test_confusion_matrix.compute().cpu().numpy()\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=class_labels )\n",
    "plt.figure(figsize=(5,5), dpi=100)\n",
    "ax = plt.axes()\n",
    "\n",
    "disp.plot(ax=ax)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
